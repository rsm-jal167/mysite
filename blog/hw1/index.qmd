---
title: Homework 1 - A/B Testing
author: Jay Lee

---


## Introduction

Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the _American Economic Review_ in 2007. The article and supporting data are available from the [AEA website](https://www.aeaweb.org/articles?id=10.1257/aer.97.5.1774) and from Innovations for Poverty Action as part of [Harvard's Dataverse](https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/27853&version=4.2).

## Data

```{python}
import pandas as pd
import numpy as np
from scipy.stats import ttest_ind
import statsmodels.formula.api as smf
import matplotlib.pyplot as plt
import statsmodels.api as sm

df = pd.read_stata("karlan_list_2007.dta")

df.head()

```



### Description

```{python}
df.shape

df.describe()

df.dtypes

```

:::: {.callout-note collapse="true"}
### Variable Definitions

| Variable             | Description                                                         |
|----------------------|---------------------------------------------------------------------|
| `treatment`          | Treatment                                                           |
| `control`            | Control                                                             |
| `ratio`              | Match ratio                                                         |
| `ratio2`             | 2:1 match ratio                                                     |
| `ratio3`             | 3:1 match ratio                                                     |
| `size`               | Match threshold                                                     |
| `size25`             | \$25,000 match threshold                                            |
| `size50`             | \$50,000 match threshold                                            |
| `size100`            | \$100,000 match threshold                                           |
| `sizeno`             | Unstated match threshold                                            |
| `ask`                | Suggested donation amount                                           |
| `askd1`              | Suggested donation was highest previous contribution                |
| `askd2`              | Suggested donation was 1.25 x highest previous contribution         |
| `askd3`              | Suggested donation was 1.50 x highest previous contribution         |
| `ask1`               | Highest previous contribution (for suggestion)                      |
| `ask2`               | 1.25 x highest previous contribution (for suggestion)               |
| `ask3`               | 1.50 x highest previous contribution (for suggestion)               |
| `amount`             | Dollars given                                                       |
| `gave`               | Gave anything                                                       |
| `amountchange`       | Change in amount given                                              |
| `hpa`                | Highest previous contribution                                       |
| `ltmedmra`           | Small prior donor: last gift was less than median \$35              |
| `freq`               | Number of prior donations                                           |
| `years`              | Number of years since initial donation                              |
| `year5`              | At least 5 years since initial donation                             |
| `mrm2`               | Number of months since last donation                                |
| `dormant`            | Already donated in 2005                                             |
| `female`             | Female                                                              |
| `couple`             | Couple                                                              |
| `state50one`         | State tag: 1 for one observation of each of 50 states; 0 otherwise  |
| `nonlit`             | Nonlitigation                                                       |
| `cases`              | Court cases from state in 2004-5 in which organization was involved |
| `statecnt`           | Percent of sample from state                                        |
| `stateresponse`      | Proportion of sample from the state who gave                        |
| `stateresponset`     | Proportion of treated sample from the state who gave                |
| `stateresponsec`     | Proportion of control sample from the state who gave                |
| `stateresponsetminc` | stateresponset - stateresponsec                                     |
| `perbush`            | State vote share for Bush                                           |
| `close25`            | State vote share for Bush between 47.5% and 52.5%                   |
| `red0`               | Red state                                                           |
| `blue0`              | Blue state                                                          |
| `redcty`             | Red county                                                          |
| `bluecty`            | Blue county                                                         |
| `pwhite`             | Proportion white within zip code                                    |
| `pblack`             | Proportion black within zip code                                    |
| `page18_39`          | Proportion age 18-39 within zip code                                |
| `ave_hh_sz`          | Average household size within zip code                              |
| `median_hhincome`    | Median household income within zip code                             |
| `powner`             | Proportion house owner within zip code                              |
| `psch_atlstba`       | Proportion who finished college within zip code                     |
| `pop_propurban`      | Proportion of population urban within zip code                      |

::::


### Balance Test 

As an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.

```{python}

# Variables to test
variables = ["mrm2", "freq", "years", "female", "ave_hh_sz"]

# Store results
results = []

for var in variables:
    temp_df = df[["treatment", var]].dropna()

    # T-test
    treatment_vals = temp_df[temp_df["treatment"] == 1][var]
    control_vals = temp_df[temp_df["treatment"] == 0][var]
    t_stat, t_pval = ttest_ind(treatment_vals, control_vals)

    # Regression
    model = smf.ols(f"{var} ~ treatment", data=temp_df).fit()
    coef = model.params["treatment"]
    reg_pval = model.pvalues["treatment"]

    # Means & stds
    mean_t = treatment_vals.mean()
    mean_c = control_vals.mean()
    std_t = treatment_vals.std()
    std_c = control_vals.std()

    results.append({
        "Variable": var,
        "Mean (Treatment)": round(mean_t, 3),
        "Mean (Control)": round(mean_c, 3),
        "Std (Treatment)": round(std_t, 3),
        "Std (Control)": round(std_c, 3),
        "T-test p-value": round(t_pval, 4),
        "Reg Coef": round(coef, 4),
        "Reg p-value": round(reg_pval, 4)
    })

# Convert to DataFrame
pd.set_option('display.max_columns', None)
balance_results = pd.DataFrame(results)
print(balance_results)


```


## Experimental Results

### Charitable Contribution Made

First, I analyze whether matched donations lead to an increased response rate of making a donation. 

```{python}

# Calculate the mean of 'gave' for control and treatment
donation_rates = df.groupby("treatment")["gave"].mean()

# Create labels and values for the plot
labels = ["Control", "Treatment"]
rates = [donation_rates[0], donation_rates[1]]

# Plot
plt.figure(figsize=(6, 4))
plt.bar(labels, rates, color='orange')
plt.title("Proportion of Donors by Group")
plt.ylabel("Proportion Who Donated")
plt.ylim(0, 0.05)
plt.grid(axis='y', linestyle='--', alpha=0.5)

# Add data labels on top of bars
for i, rate in enumerate(rates):
    plt.text(i, rate + 0.01, f"{rate:.3f}", ha='center', va='bottom')

plt.show()


```


```{python}
# Drop any missing values in relevant columns
df_clean = df.dropna(subset=["gave", "treatment"])

# --- T-TEST ---
gave_treatment = df_clean[df_clean["treatment"] == 1]["gave"]
gave_control = df_clean[df_clean["treatment"] == 0]["gave"]

t_stat, p_val = ttest_ind(gave_treatment, gave_control)

# --- LINEAR REGRESSION ---
model = smf.ols("gave ~ treatment", data=df_clean).fit()
coef = model.params["treatment"]
reg_pval = model.pvalues["treatment"]

# --- PRINT RESULTS ---
print("T-Test Results:")
print(f"  t-statistic = {t_stat:.4f}")
print(f"  p-value     = {p_val:.4f}")

print("\nLinear Regression Results:")
print(f"  Coefficient = {coef:.4f}")
print(f"  p-value     = {reg_pval:.4f}")

# Interpretation in plain English
if p_val < 0.05:
    print("\nInterpretation:")
    print("  The treatment group was significantly more likely to donate than the control group.")
    print("  This suggests that the experimental message or treatment had a real behavioral impact.")
else:
    print("\nInterpretation:")
    print("  There is no statistically significant difference in donation rates between groups.")

```


```{python}
df_probit = df.dropna(subset=["gave", "treatment"])

# Define independent (X) and dependent (y) variables
X = sm.add_constant(df_probit["treatment"])  # Add constant (intercept)
y = df_probit["gave"]

# Fit the probit model
probit_model = sm.Probit(y, X).fit()

# Print summary
print(probit_model.summary())

```




### Differences between Match Rates

Next, I assess the effectiveness of different sizes of matched donations on the response rate.


```{python}
# Clean and filter relevant data
df_ratio_test = df.dropna(subset=["gave", "ratio2", "ratio3"])

# Define match ratio groups
group_1_to_1 = df_ratio_test[(df_ratio_test["ratio2"] == 0) & (df_ratio_test["ratio3"] == 0)]["gave"]
group_2_to_1 = df_ratio_test[df_ratio_test["ratio2"] == 1]["gave"]
group_3_to_1 = df_ratio_test[df_ratio_test["ratio3"] == 1]["gave"]

# T-tests
t_stat_2, p_val_2 = ttest_ind(group_1_to_1, group_2_to_1)
t_stat_3, p_val_3 = ttest_ind(group_1_to_1, group_3_to_1)

# Print results
print("T-Test: 2:1 Match vs 1:1 Match")
print(f"  t-statistic = {t_stat_2:.4f}")
print(f"  p-value     = {p_val_2:.4f}\n")

print("T-Test: 3:1 Match vs 1:1 Match")
print(f"  t-statistic = {t_stat_3:.4f}")
print(f"  p-value     = {p_val_3:.4f}")

# Interpretation
print("\nInterpretation:")
if p_val_2 < 0.05 or p_val_3 < 0.05:
    print("There is a statistically significant difference in donation rates between groups.")
    print("However, the direction of the effect shows that higher match ratios (2:1 and 3:1) do NOT increase donation likelihood.")
    print("This supports the paper's claim on page 8 that 'larger match ratios... had no additional impact.'")
else:
    print("There is no statistically significant difference between the groups.")
    print("This confirms that increasing the match ratio beyond 1:1 does not lead to higher donation rates, as the authors suggest.")

```


```{python}

# Create 'ratio1' dummy: 1 if both ratio2 and ratio3 are 0 (i.e., it's a 1:1 match)
df_ratio_test["ratio1"] = ((df_ratio_test["ratio2"] == 0) & (df_ratio_test["ratio3"] == 0)).astype(int)

# Run regression
model = smf.ols("gave ~ ratio1 + ratio2 + ratio3", data=df_ratio_test).fit()

# Display regression results
print(model.summary())
```


### Size of Charitable Contribution

In this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.


```{python}
# Drop missing values from the donation amount and treatment columns
df_amount = df.dropna(subset=["amount", "treatment"])

# --- T-TEST ---
donation_treatment = df_amount[df_amount["treatment"] == 1]["amount"]
donation_control = df_amount[df_amount["treatment"] == 0]["amount"]

t_stat, p_val = ttest_ind(donation_treatment, donation_control)

print("T-Test: Donation Amount by Treatment")
print(f"  t-statistic = {t_stat:.4f}")
print(f"  p-value     = {p_val:.4f}\n")

# --- LINEAR REGRESSION ---
model = smf.ols("amount ~ treatment", data=df_amount).fit()
print("Linear Regression: Donation Amount ~ Treatment")
print(model.summary())

```
If the t-test or regression shows a statistically significant difference, it means that the treatment influenced the size of donations, not just whether people donated.

If not significant, then the treatment increased response rate, but not donation size, which aligns with the "extensive margin" effect described in behavioral economics.

```{python}
# Filter to people who made a donation (amount > 0)
df_positive_donors = df[(df["amount"] > 0) & df["treatment"].notna()]

# --- T-TEST ---
donation_treatment = df_positive_donors[df_positive_donors["treatment"] == 1]["amount"]
donation_control = df_positive_donors[df_positive_donors["treatment"] == 0]["amount"]

t_stat, p_val = ttest_ind(donation_treatment, donation_control)

print("T-Test (Donors Only): Donation Amount by Treatment")
print(f"  t-statistic = {t_stat:.4f}")
print(f"  p-value     = {p_val:.4f}\n")

# --- REGRESSION ---
model = smf.ols("amount ~ treatment", data=df_positive_donors).fit()
print("Linear Regression (Donors Only): Donation Amount ~ Treatment")
print(model.summary())

```

This analysis isolates the intensive margin: how much people give once they’ve decided to donate.

If the treatment coefficient is not significant, it suggests the treatment affected whether people give (extensive margin), but not how much they give. If it's significant, then the treatment changes the amount donated as well.

Yes, the treatment coefficient has a causal interpretation only if random assignment is preserved and we're not conditioning on post-treatment behavior.



```{python}
# Keep only donors (amount > 0)
df_donors = df[df["amount"] > 0]

# Split into treatment and control groups
treatment_donors = df_donors[df_donors["treatment"] == 1]["amount"]
control_donors = df_donors[df_donors["treatment"] == 0]["amount"]

# Calculate group means
mean_treatment = treatment_donors.mean()
mean_control = control_donors.mean()

# Plotting
plt.figure(figsize=(12, 5))

# Control group plot
plt.subplot(1, 2, 1)
plt.hist(control_donors, bins=30, edgecolor='black')
plt.axvline(mean_control, color='red', linestyle='dashed', linewidth=2, label=f"Mean = ${mean_control:.2f}")
plt.title("Control Group Donations (Donors Only)")
plt.xlabel("Donation Amount ($)")
plt.ylabel("Frequency")
plt.legend()

# Treatment group plot
plt.subplot(1, 2, 2)
plt.hist(treatment_donors, bins=30, edgecolor='black')
plt.axvline(mean_treatment, color='red', linestyle='dashed', linewidth=2, label=f"Mean = ${mean_treatment:.2f}")
plt.title("Treatment Group Donations (Donors Only)")
plt.xlabel("Donation Amount ($)")
plt.ylabel("Frequency")
plt.legend()

plt.tight_layout()
plt.show()

```



## Simulation Experiment

As a reminder of how the t-statistic "works," in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.

Suppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made. 

Further suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.

### Law of Large Numbers


```{python}
# Set seed for reproducibility
np.random.seed(42)

# Simulate 10,000 Bernoulli draws for control (p = 0.018) and treatment (p = 0.022)
control_draws = np.random.binomial(n=1, p=0.018, size=10000)
treatment_draws = np.random.binomial(n=1, p=0.022, size=10000)

# Calculate the differences between treatment and control draws
differences = treatment_draws - control_draws

# Compute the cumulative average of the differences
cumulative_avg = np.cumsum(differences) / np.arange(1, len(differences) + 1)

# Plotting
plt.figure(figsize=(10, 5))
plt.plot(cumulative_avg, color='orange', label='Cumulative Average of Differences')
plt.axhline(y=0.004, color='red', linestyle='--', linewidth=2, label='True Treatment Effect (0.004)')
plt.title("Simulation: Law of Large Numbers for Treatment Effect")
plt.xlabel("Number of Simulations")
plt.ylabel("Cumulative Average Difference")
plt.grid(True, linestyle='--', alpha=0.6)
plt.legend()
plt.tight_layout()
plt.show()

```

The orange line shows the cumulative average difference in donation rates over increasing sample sizes.

The red dashed line is the true average treatment effect: 0.022 - 0.018 = 0.004

At first, the cumulative difference is noisy — it jumps around. As more samples are included, the average "settles down" near the true effect of 0.004. This demonstrates that with large enough samples, random variation diminishes, revealing the true underlying effect.

### Central Limit Theorem


```{python}
# Parameters
sample_sizes = [50, 200, 500, 1000]
num_repeats = 1000
p_control = 0.018
p_treatment = 0.022

# Set up subplots
fig, axes = plt.subplots(1, 4, figsize=(18, 4), sharey=True)

# Loop through each sample size
for i, n in enumerate(sample_sizes):
    avg_diffs = []
    for _ in range(num_repeats):
        control = np.random.binomial(1, p_control, n)
        treatment = np.random.binomial(1, p_treatment, n)
        avg_diff = treatment.mean() - control.mean()
        avg_diffs.append(avg_diff)

    # Plot histogram of average treatment effects
    ax = axes[i]
    ax.hist(avg_diffs, bins=30, edgecolor='black', color='orange')
    ax.axvline(np.mean(avg_diffs), color='red', linestyle='--', linewidth=2, label="Mean")
    ax.set_title(f"Sample Size = {n}")
    ax.set_xlabel("Avg Treatment Effect")
    if i == 0:
        ax.set_ylabel("Frequency")

plt.suptitle("Central Limit Theorem: Distribution of Average Treatment Effects", fontsize=14)
plt.tight_layout(rect=[0, 0, 1, 0.92])
plt.show()

```

Each plot shows the distribution of average treatment effects calculated from 1,000 repeated samples at different sample sizes: 50, 200, 500, and 1000.

As the sample size increases: 1. The distribution becomes less spread out (narrower) 2. The shape becomes more symmetric and bell-shaped, resembling a normal distribution 3. The mean converges around the true treatment effect (~0.004), shown by the red dashed line

This illustrates the CLT: the sampling distribution of the mean tends toward a normal distribution as sample size grows, regardless of the underlying data distribution.




