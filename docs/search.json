[
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Jay’s Resume",
    "section": "",
    "text": "Last updated 04/05/2025\nDownload PDF file."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jay Lee",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "blog/hw1/index.html",
    "href": "blog/hw1/index.html",
    "title": "Homework 1 - A/B Testing",
    "section": "",
    "text": "Question 1\n\nimport pandas as pd\n\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\ndf.head()\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.0\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.0\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.0\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.0\n\n\n\n\n5 rows × 51 columns"
  },
  {
    "objectID": "blog/hw1/hw1.html",
    "href": "blog/hw1/hw1.html",
    "title": "Jay Lee",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\nDescription\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\ndf.head()\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.0\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.0\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.0\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.0\n\n\n\n\n5 rows × 51 columns\ndf.shape\n\n(50083, 51)\ndf.describe()\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio2\nratio3\nsize25\nsize50\nsize100\nsizeno\naskd1\naskd2\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\ncount\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n50083.000000\n...\n49978.000000\n49978.000000\n48217.000000\n48047.000000\n48217.000000\n48221.000000\n48209.000000\n48214.000000\n48215.000000\n48217.000000\n\n\nmean\n0.666813\n0.333187\n0.222311\n0.222211\n0.166723\n0.166623\n0.166723\n0.166743\n0.222311\n0.222291\n...\n0.510245\n0.488715\n0.819599\n0.086710\n0.321694\n2.429012\n54815.700533\n0.669418\n0.391661\n0.871968\n\n\nstd\n0.471357\n0.471357\n0.415803\n0.415736\n0.372732\n0.372643\n0.372732\n0.372750\n0.415803\n0.415790\n...\n0.499900\n0.499878\n0.168560\n0.135868\n0.103039\n0.378105\n22027.316665\n0.193405\n0.186599\n0.258633\n\n\nmin\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.009418\n0.000000\n0.000000\n0.000000\n5000.000000\n0.000000\n0.000000\n0.000000\n\n\n25%\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n0.000000\n0.000000\n0.755845\n0.014729\n0.258311\n2.210000\n39181.000000\n0.560222\n0.235647\n0.884929\n\n\n50%\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n0.000000\n0.872797\n0.036554\n0.305534\n2.440000\n50673.000000\n0.712296\n0.373744\n1.000000\n\n\n75%\n1.000000\n1.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n0.000000\n...\n1.000000\n1.000000\n0.938827\n0.090882\n0.369132\n2.660000\n66005.000000\n0.816798\n0.530036\n1.000000\n\n\nmax\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n1.000000\n...\n1.000000\n1.000000\n1.000000\n0.989622\n0.997544\n5.270000\n200001.000000\n1.000000\n1.000000\n1.000000\n\n\n\n\n8 rows × 48 columns\ndf.dtypes\n\ntreatment                 int8\ncontrol                   int8\nratio                 category\nratio2                    int8\nratio3                    int8\nsize                  category\nsize25                    int8\nsize50                    int8\nsize100                   int8\nsizeno                    int8\nask                   category\naskd1                     int8\naskd2                     int8\naskd3                     int8\nask1                     int16\nask2                     int16\nask3                     int16\namount                 float32\ngave                      int8\namountchange           float32\nhpa                    float32\nltmedmra                  int8\nfreq                     int16\nyears                  float64\nyear5                     int8\nmrm2                   float64\ndormant                   int8\nfemale                 float64\ncouple                 float64\nstate50one                int8\nnonlit                 float64\ncases                  float64\nstatecnt               float32\nstateresponse          float32\nstateresponset         float32\nstateresponsec         float32\nstateresponsetminc     float32\nperbush                float32\nclose25                float64\nred0                   float64\nblue0                  float64\nredcty                 float64\nbluecty                float64\npwhite                 float32\npblack                 float32\npage18_39              float32\nave_hh_sz              float32\nmedian_hhincome        float64\npowner                 float32\npsch_atlstba           float32\npop_propurban          float32\ndtype: object"
  },
  {
    "objectID": "blog/hw1/hw1.html#experimental-results",
    "href": "blog/hw1/hw1.html#experimental-results",
    "title": "Jay Lee",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\n\n# Calculate the mean of 'gave' for control and treatment\ndonation_rates = df.groupby(\"treatment\")[\"gave\"].mean()\n\n# Create labels and values for the plot\nlabels = [\"Control\", \"Treatment\"]\nrates = [donation_rates[0], donation_rates[1]]\n\n# Plot\nplt.figure(figsize=(6, 4))\nplt.bar(labels, rates, color='orange')\nplt.title(\"Proportion of Donors by Group\")\nplt.ylabel(\"Proportion Who Donated\")\nplt.ylim(0, 0.05)\nplt.grid(axis='y', linestyle='--', alpha=0.5)\n\n# Add data labels on top of bars\nfor i, rate in enumerate(rates):\n    plt.text(i, rate + 0.01, f\"{rate:.3f}\", ha='center', va='bottom')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n# Drop any missing values in relevant columns\ndf_clean = df.dropna(subset=[\"gave\", \"treatment\"])\n\n# --- T-TEST ---\ngave_treatment = df_clean[df_clean[\"treatment\"] == 1][\"gave\"]\ngave_control = df_clean[df_clean[\"treatment\"] == 0][\"gave\"]\n\nt_stat, p_val = ttest_ind(gave_treatment, gave_control)\n\n# --- LINEAR REGRESSION ---\nmodel = smf.ols(\"gave ~ treatment\", data=df_clean).fit()\ncoef = model.params[\"treatment\"]\nreg_pval = model.pvalues[\"treatment\"]\n\n# --- PRINT RESULTS ---\nprint(\"T-Test Results:\")\nprint(f\"  t-statistic = {t_stat:.4f}\")\nprint(f\"  p-value     = {p_val:.4f}\")\n\nprint(\"\\nLinear Regression Results:\")\nprint(f\"  Coefficient = {coef:.4f}\")\nprint(f\"  p-value     = {reg_pval:.4f}\")\n\n# Interpretation in plain English\nif p_val &lt; 0.05:\n    print(\"\\nInterpretation:\")\n    print(\"  The treatment group was significantly more likely to donate than the control group.\")\n    print(\"  This suggests that the experimental message or treatment had a real behavioral impact.\")\nelse:\n    print(\"\\nInterpretation:\")\n    print(\"  There is no statistically significant difference in donation rates between groups.\")\n\nT-Test Results:\n  t-statistic = 3.1014\n  p-value     = 0.0019\n\nLinear Regression Results:\n  Coefficient = 0.0042\n  p-value     = 0.0019\n\nInterpretation:\n  The treatment group was significantly more likely to donate than the control group.\n  This suggests that the experimental message or treatment had a real behavioral impact.\n\n\n\ndf_probit = df.dropna(subset=[\"gave\", \"treatment\"])\n\n# Define independent (X) and dependent (y) variables\nX = sm.add_constant(df_probit[\"treatment\"])  # Add constant (intercept)\ny = df_probit[\"gave\"]\n\n# Fit the probit model\nprobit_model = sm.Probit(y, X).fit()\n\n# Print summary\nprint(probit_model.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Wed, 23 Apr 2025   Pseudo R-squ.:               0.0009783\nTime:                        21:32:46   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\n\n\n\n\nDifferences between Match Rates\n\n# Clean and filter relevant data\ndf_ratio_test = df.dropna(subset=[\"gave\", \"ratio2\", \"ratio3\"])\n\n# Define match ratio groups\ngroup_1_to_1 = df_ratio_test[(df_ratio_test[\"ratio2\"] == 0) & (df_ratio_test[\"ratio3\"] == 0)][\"gave\"]\ngroup_2_to_1 = df_ratio_test[df_ratio_test[\"ratio2\"] == 1][\"gave\"]\ngroup_3_to_1 = df_ratio_test[df_ratio_test[\"ratio3\"] == 1][\"gave\"]\n\n# T-tests\nt_stat_2, p_val_2 = ttest_ind(group_1_to_1, group_2_to_1)\nt_stat_3, p_val_3 = ttest_ind(group_1_to_1, group_3_to_1)\n\n# Print results\nprint(\"T-Test: 2:1 Match vs 1:1 Match\")\nprint(f\"  t-statistic = {t_stat_2:.4f}\")\nprint(f\"  p-value     = {p_val_2:.4f}\\n\")\n\nprint(\"T-Test: 3:1 Match vs 1:1 Match\")\nprint(f\"  t-statistic = {t_stat_3:.4f}\")\nprint(f\"  p-value     = {p_val_3:.4f}\")\n\n# Interpretation\nprint(\"\\nInterpretation:\")\nif p_val_2 &lt; 0.05 or p_val_3 &lt; 0.05:\n    print(\"There is a statistically significant difference in donation rates between groups.\")\n    print(\"However, the direction of the effect shows that higher match ratios (2:1 and 3:1) do NOT increase donation likelihood.\")\n    print(\"This supports the paper's claim on page 8 that 'larger match ratios... had no additional impact.'\")\nelse:\n    print(\"There is no statistically significant difference between the groups.\")\n    print(\"This confirms that increasing the match ratio beyond 1:1 does not lead to higher donation rates, as the authors suggest.\")\n\nT-Test: 2:1 Match vs 1:1 Match\n  t-statistic = -2.3020\n  p-value     = 0.0213\n\nT-Test: 3:1 Match vs 1:1 Match\n  t-statistic = -2.3636\n  p-value     = 0.0181\n\nInterpretation:\nThere is a statistically significant difference in donation rates between groups.\nHowever, the direction of the effect shows that higher match ratios (2:1 and 3:1) do NOT increase donation likelihood.\nThis supports the paper's claim on page 8 that 'larger match ratios... had no additional impact.'\n\n\n\n# Create 'ratio1' dummy: 1 if both ratio2 and ratio3 are 0 (i.e., it's a 1:1 match)\ndf_ratio_test[\"ratio1\"] = ((df_ratio_test[\"ratio2\"] == 0) & (df_ratio_test[\"ratio3\"] == 0)).astype(int)\n\n# Run regression\nmodel = smf.ols(\"gave ~ ratio1 + ratio2 + ratio3\", data=df_ratio_test).fit()\n\n# Display regression results\nprint(model.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     2.742\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):             0.0416\nTime:                        21:37:36   Log-Likelihood:                 26629.\nNo. Observations:               50083   AIC:                        -5.325e+04\nDf Residuals:                   50079   BIC:                        -5.321e+04\nDf Model:                           3                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept   1.229e+10   1.54e+11      0.080      0.936   -2.89e+11    3.14e+11\nratio1     -1.229e+10   1.54e+11     -0.080      0.936   -3.14e+11    2.89e+11\nratio2     -1.229e+10   1.54e+11     -0.080      0.936   -3.14e+11    2.89e+11\nratio3     -1.229e+10   1.54e+11     -0.080      0.936   -3.14e+11    2.89e+11\n==============================================================================\nOmnibus:                    59815.680   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4317584.682\nSkew:                           6.741   Prob(JB):                         0.00\nKurtosis:                      46.443   Cond. No.                     5.80e+14\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The smallest eigenvalue is 2.13e-25. This might indicate that there are\nstrong multicollinearity problems or that the design matrix is singular.\n\n\n\n\nSize of Charitable Contribution\n\n# Drop missing values from the donation amount and treatment columns\ndf_amount = df.dropna(subset=[\"amount\", \"treatment\"])\n\n# --- T-TEST ---\ndonation_treatment = df_amount[df_amount[\"treatment\"] == 1][\"amount\"]\ndonation_control = df_amount[df_amount[\"treatment\"] == 0][\"amount\"]\n\nt_stat, p_val = ttest_ind(donation_treatment, donation_control)\n\nprint(\"T-Test: Donation Amount by Treatment\")\nprint(f\"  t-statistic = {t_stat:.4f}\")\nprint(f\"  p-value     = {p_val:.4f}\\n\")\n\n# --- LINEAR REGRESSION ---\nmodel = smf.ols(\"amount ~ treatment\", data=df_amount).fit()\nprint(\"Linear Regression: Donation Amount ~ Treatment\")\nprint(model.summary())\n\nT-Test: Donation Amount by Treatment\n  t-statistic = 1.8605\n  p-value     = 0.0628\n\nLinear Regression: Donation Amount ~ Treatment\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     3.461\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):             0.0628\nTime:                        21:38:21   Log-Likelihood:            -1.7946e+05\nNo. Observations:               50083   AIC:                         3.589e+05\nDf Residuals:                   50081   BIC:                         3.589e+05\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.8133      0.067     12.063      0.000       0.681       0.945\ntreatment      0.1536      0.083      1.861      0.063      -0.008       0.315\n==============================================================================\nOmnibus:                    96861.113   Durbin-Watson:                   2.008\nProb(Omnibus):                  0.000   Jarque-Bera (JB):        240735713.635\nSkew:                          15.297   Prob(JB):                         0.00\nKurtosis:                     341.269   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\nIf the t-test or regression shows a statistically significant difference, it means that the treatment influenced the size of donations, not just whether people donated.\n\n\nIf not significant, then the treatment increased response rate, but not donation size, which aligns with the “extensive margin” effect described in behavioral economics.\n\n# Filter to people who made a donation (amount &gt; 0)\ndf_positive_donors = df[(df[\"amount\"] &gt; 0) & df[\"treatment\"].notna()]\n\n# --- T-TEST ---\ndonation_treatment = df_positive_donors[df_positive_donors[\"treatment\"] == 1][\"amount\"]\ndonation_control = df_positive_donors[df_positive_donors[\"treatment\"] == 0][\"amount\"]\n\nt_stat, p_val = ttest_ind(donation_treatment, donation_control)\n\nprint(\"T-Test (Donors Only): Donation Amount by Treatment\")\nprint(f\"  t-statistic = {t_stat:.4f}\")\nprint(f\"  p-value     = {p_val:.4f}\\n\")\n\n# --- REGRESSION ---\nmodel = smf.ols(\"amount ~ treatment\", data=df_positive_donors).fit()\nprint(\"Linear Regression (Donors Only): Donation Amount ~ Treatment\")\nprint(model.summary())\n\nT-Test (Donors Only): Donation Amount by Treatment\n  t-statistic = -0.5808\n  p-value     = 0.5615\n\nLinear Regression (Donors Only): Donation Amount ~ Treatment\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.001\nMethod:                 Least Squares   F-statistic:                    0.3374\nDate:                Wed, 23 Apr 2025   Prob (F-statistic):              0.561\nTime:                        21:44:20   Log-Likelihood:                -5326.8\nNo. Observations:                1034   AIC:                         1.066e+04\nDf Residuals:                    1032   BIC:                         1.067e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     45.5403      2.423     18.792      0.000      40.785      50.296\ntreatment     -1.6684      2.872     -0.581      0.561      -7.305       3.968\n==============================================================================\nOmnibus:                      587.258   Durbin-Watson:                   2.031\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             5623.279\nSkew:                           2.464   Prob(JB):                         0.00\nKurtosis:                      13.307   Cond. No.                         3.49\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\n\n\nThis analysis isolates the intensive margin: how much people give once they’ve decided to donate.\n\n\nIf the treatment coefficient is not significant, it suggests the treatment affected whether people give (extensive margin), but not how much they give. If it’s significant, then the treatment changes the amount donated as well.\n\n\nYes, the treatment coefficient has a causal interpretation only if random assignment is preserved and we’re not conditioning on post-treatment behavior.\n\n# Keep only donors (amount &gt; 0)\ndf_donors = df[df[\"amount\"] &gt; 0]\n\n# Split into treatment and control groups\ntreatment_donors = df_donors[df_donors[\"treatment\"] == 1][\"amount\"]\ncontrol_donors = df_donors[df_donors[\"treatment\"] == 0][\"amount\"]\n\n# Calculate group means\nmean_treatment = treatment_donors.mean()\nmean_control = control_donors.mean()\n\n# Plotting\nplt.figure(figsize=(12, 5))\n\n# Control group plot\nplt.subplot(1, 2, 1)\nplt.hist(control_donors, bins=30, edgecolor='black')\nplt.axvline(mean_control, color='red', linestyle='dashed', linewidth=2, label=f\"Mean = ${mean_control:.2f}\")\nplt.title(\"Control Group Donations (Donors Only)\")\nplt.xlabel(\"Donation Amount ($)\")\nplt.ylabel(\"Frequency\")\nplt.legend()\n\n# Treatment group plot\nplt.subplot(1, 2, 2)\nplt.hist(treatment_donors, bins=30, edgecolor='black')\nplt.axvline(mean_treatment, color='red', linestyle='dashed', linewidth=2, label=f\"Mean = ${mean_treatment:.2f}\")\nplt.title(\"Treatment Group Donations (Donors Only)\")\nplt.xlabel(\"Donation Amount ($)\")\nplt.ylabel(\"Frequency\")\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nLaw of Large Numbers\n\n# Set seed for reproducibility\nnp.random.seed(42)\n\n# Simulate 10,000 Bernoulli draws for control (p = 0.018) and treatment (p = 0.022)\ncontrol_draws = np.random.binomial(n=1, p=0.018, size=10000)\ntreatment_draws = np.random.binomial(n=1, p=0.022, size=10000)\n\n# Calculate the differences between treatment and control draws\ndifferences = treatment_draws - control_draws\n\n# Compute the cumulative average of the differences\ncumulative_avg = np.cumsum(differences) / np.arange(1, len(differences) + 1)\n\n# Plotting\nplt.figure(figsize=(10, 5))\nplt.plot(cumulative_avg, color='orange', label='Cumulative Average of Differences')\nplt.axhline(y=0.004, color='red', linestyle='--', linewidth=2, label='True Treatment Effect (0.004)')\nplt.title(\"Simulation: Law of Large Numbers for Treatment Effect\")\nplt.xlabel(\"Number of Simulations\")\nplt.ylabel(\"Cumulative Average Difference\")\nplt.grid(True, linestyle='--', alpha=0.6)\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\nThe orange line shows the cumulative average difference in donation rates over increasing sample sizes.\n\n\nThe red dashed line is the true average treatment effect: 0.022 - 0.018 = 0.004\n\n\nAt first, the cumulative difference is noisy — it jumps around. As more samples are included, the average “settles down” near the true effect of 0.004. This demonstrates that with large enough samples, random variation diminishes, revealing the true underlying effect.\n\n\n\nCentral Limit Theorem\n\n# Parameters\nsample_sizes = [50, 200, 500, 1000]\nnum_repeats = 1000\np_control = 0.018\np_treatment = 0.022\n\n# Set up subplots\nfig, axes = plt.subplots(1, 4, figsize=(18, 4), sharey=True)\n\n# Loop through each sample size\nfor i, n in enumerate(sample_sizes):\n    avg_diffs = []\n    for _ in range(num_repeats):\n        control = np.random.binomial(1, p_control, n)\n        treatment = np.random.binomial(1, p_treatment, n)\n        avg_diff = treatment.mean() - control.mean()\n        avg_diffs.append(avg_diff)\n\n    # Plot histogram of average treatment effects\n    ax = axes[i]\n    ax.hist(avg_diffs, bins=30, edgecolor='black', color='orange')\n    ax.axvline(np.mean(avg_diffs), color='red', linestyle='--', linewidth=2, label=\"Mean\")\n    ax.set_title(f\"Sample Size = {n}\")\n    ax.set_xlabel(\"Avg Treatment Effect\")\n    if i == 0:\n        ax.set_ylabel(\"Frequency\")\n\nplt.suptitle(\"Central Limit Theorem: Distribution of Average Treatment Effects\", fontsize=14)\nplt.tight_layout(rect=[0, 0, 1, 0.92])\nplt.show()\n\n\n\n\n\n\n\n\n\nEach plot shows the distribution of average treatment effects calculated from 1,000 repeated samples at different sample sizes: 50, 200, 500, and 1000.\n\n\nAs the sample size increases: 1. The distribution becomes less spread out (narrower) 2. The shape becomes more symmetric and bell-shaped, resembling a normal distribution 3. The mean converges around the true treatment effect (~0.004), shown by the red dashed line\n\n\nThis illustrates the CLT: the sampling distribution of the mean tends toward a normal distribution as sample size grows, regardless of the underlying data distribution."
  },
  {
    "objectID": "blog/hw1/hw1_questions.html",
    "href": "blog/hw1/hw1_questions.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\n\nimport pandas as pd\nimport numpy as np\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\n\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\ndf.head()\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.0\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.0\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.0\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.0\n\n\n\n\n5 rows × 51 columns\n\n\n\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/hw1/hw1_questions.html#introduction",
    "href": "blog/hw1/hw1_questions.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard’s Dataverse.\n\nimport pandas as pd\nimport numpy as np\nfrom scipy.stats import ttest_ind\nimport statsmodels.formula.api as smf\nimport matplotlib.pyplot as plt\nimport statsmodels.api as sm\n\ndf = pd.read_stata(\"karlan_list_2007.dta\")\n\ndf.head()\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.0\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.0\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.0\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.0\n\n\n\n\n5 rows × 51 columns\n\n\n\nThis project seeks to replicate their results."
  },
  {
    "objectID": "blog/hw1/hw1_questions.html#data",
    "href": "blog/hw1/hw1_questions.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\n\ndf.shape\n\ndf.describe()\n\ndf.dtypes\n\ntreatment                 int8\ncontrol                   int8\nratio                 category\nratio2                    int8\nratio3                    int8\nsize                  category\nsize25                    int8\nsize50                    int8\nsize100                   int8\nsizeno                    int8\nask                   category\naskd1                     int8\naskd2                     int8\naskd3                     int8\nask1                     int16\nask2                     int16\nask3                     int16\namount                 float32\ngave                      int8\namountchange           float32\nhpa                    float32\nltmedmra                  int8\nfreq                     int16\nyears                  float64\nyear5                     int8\nmrm2                   float64\ndormant                   int8\nfemale                 float64\ncouple                 float64\nstate50one                int8\nnonlit                 float64\ncases                  float64\nstatecnt               float32\nstateresponse          float32\nstateresponset         float32\nstateresponsec         float32\nstateresponsetminc     float32\nperbush                float32\nclose25                float64\nred0                   float64\nblue0                  float64\nredcty                 float64\nbluecty                float64\npwhite                 float32\npblack                 float32\npage18_39              float32\nave_hh_sz              float32\nmedian_hhincome        float64\npowner                 float32\npsch_atlstba           float32\npop_propurban          float32\ndtype: object\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\n# Variables to test\nvariables = [\"mrm2\", \"freq\", \"years\", \"female\", \"ave_hh_sz\"]\n\n# Store results\nresults = []\n\nfor var in variables:\n    temp_df = df[[\"treatment\", var]].dropna()\n\n    # T-test\n    treatment_vals = temp_df[temp_df[\"treatment\"] == 1][var]\n    control_vals = temp_df[temp_df[\"treatment\"] == 0][var]\n    t_stat, t_pval = ttest_ind(treatment_vals, control_vals)\n\n    # Regression\n    model = smf.ols(f\"{var} ~ treatment\", data=temp_df).fit()\n    coef = model.params[\"treatment\"]\n    reg_pval = model.pvalues[\"treatment\"]\n\n    # Means & stds\n    mean_t = treatment_vals.mean()\n    mean_c = control_vals.mean()\n    std_t = treatment_vals.std()\n    std_c = control_vals.std()\n\n    results.append({\n        \"Variable\": var,\n        \"Mean (Treatment)\": round(mean_t, 3),\n        \"Mean (Control)\": round(mean_c, 3),\n        \"Std (Treatment)\": round(std_t, 3),\n        \"Std (Control)\": round(std_c, 3),\n        \"T-test p-value\": round(t_pval, 4),\n        \"Reg Coef\": round(coef, 4),\n        \"Reg p-value\": round(reg_pval, 4)\n    })\n\n# Convert to DataFrame\npd.set_option('display.max_columns', None)\nbalance_results = pd.DataFrame(results)\nprint(balance_results)\n\n    Variable  Mean (Treatment)  Mean (Control)  Std (Treatment)  \\\n0       mrm2            13.012          12.998           12.086   \n1       freq             8.035           8.047           11.390   \n2      years             6.078           6.136            5.442   \n3     female             0.275           0.283            0.447   \n4  ave_hh_sz             2.430           2.427            0.378   \n\n   Std (Control)  T-test p-value  Reg Coef  Reg p-value  \n0         12.074          0.9049    0.0137       0.9049  \n1         11.404          0.9117   -0.0120       0.9117  \n2          5.625          0.2700   -0.0575       0.2700  \n3          0.450          0.0787   -0.0075       0.0787  \n4          0.379          0.4098    0.0030       0.4098"
  },
  {
    "objectID": "blog/hw1/hw1_questions.html#experimental-results",
    "href": "blog/hw1/hw1_questions.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\n# Calculate the mean of 'gave' for control and treatment\ndonation_rates = df.groupby(\"treatment\")[\"gave\"].mean()\n\n# Create labels and values for the plot\nlabels = [\"Control\", \"Treatment\"]\nrates = [donation_rates[0], donation_rates[1]]\n\n# Plot\nplt.figure(figsize=(6, 4))\nplt.bar(labels, rates, color='orange')\nplt.title(\"Proportion of Donors by Group\")\nplt.ylabel(\"Proportion Who Donated\")\nplt.ylim(0, 0.05)\nplt.grid(axis='y', linestyle='--', alpha=0.5)\n\n# Add data labels on top of bars\nfor i, rate in enumerate(rates):\n    plt.text(i, rate + 0.01, f\"{rate:.3f}\", ha='center', va='bottom')\n\nplt.show()\n\n\n\n\n\n\n\n\n\n# Drop any missing values in relevant columns\ndf_clean = df.dropna(subset=[\"gave\", \"treatment\"])\n\n# --- T-TEST ---\ngave_treatment = df_clean[df_clean[\"treatment\"] == 1][\"gave\"]\ngave_control = df_clean[df_clean[\"treatment\"] == 0][\"gave\"]\n\nt_stat, p_val = ttest_ind(gave_treatment, gave_control)\n\n# --- LINEAR REGRESSION ---\nmodel = smf.ols(\"gave ~ treatment\", data=df_clean).fit()\ncoef = model.params[\"treatment\"]\nreg_pval = model.pvalues[\"treatment\"]\n\n# --- PRINT RESULTS ---\nprint(\"T-Test Results:\")\nprint(f\"  t-statistic = {t_stat:.4f}\")\nprint(f\"  p-value     = {p_val:.4f}\")\n\nprint(\"\\nLinear Regression Results:\")\nprint(f\"  Coefficient = {coef:.4f}\")\nprint(f\"  p-value     = {reg_pval:.4f}\")\n\n# Interpretation in plain English\nif p_val &lt; 0.05:\n    print(\"\\nInterpretation:\")\n    print(\"  The treatment group was significantly more likely to donate than the control group.\")\n    print(\"  This suggests that the experimental message or treatment had a real behavioral impact.\")\nelse:\n    print(\"\\nInterpretation:\")\n    print(\"  There is no statistically significant difference in donation rates between groups.\")\n\nT-Test Results:\n  t-statistic = 3.1014\n  p-value     = 0.0019\n\nLinear Regression Results:\n  Coefficient = 0.0042\n  p-value     = 0.0019\n\nInterpretation:\n  The treatment group was significantly more likely to donate than the control group.\n  This suggests that the experimental message or treatment had a real behavioral impact.\n\n\n\ndf_probit = df.dropna(subset=[\"gave\", \"treatment\"])\n\n# Define independent (X) and dependent (y) variables\nX = sm.add_constant(df_probit[\"treatment\"])  # Add constant (intercept)\ny = df_probit[\"gave\"]\n\n# Fit the probit model\nprobit_model = sm.Probit(y, X).fit()\n\n# Print summary\nprint(probit_model.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n                          Probit Regression Results                           \n==============================================================================\nDep. Variable:                   gave   No. Observations:                50083\nModel:                         Probit   Df Residuals:                    50081\nMethod:                           MLE   Df Model:                            1\nDate:                Sat, 26 Apr 2025   Pseudo R-squ.:               0.0009783\nTime:                        12:13:15   Log-Likelihood:                -5030.5\nconverged:                       True   LL-Null:                       -5035.4\nCovariance Type:            nonrobust   LLR p-value:                  0.001696\n==============================================================================\n                 coef    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\nconst         -2.1001      0.023    -90.073      0.000      -2.146      -2.054\ntreatment      0.0868      0.028      3.113      0.002       0.032       0.141\n==============================================================================\n\n\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\n# Clean and filter relevant data\ndf_ratio_test = df.dropna(subset=[\"gave\", \"ratio2\", \"ratio3\"])\n\n# Define match ratio groups\ngroup_1_to_1 = df_ratio_test[(df_ratio_test[\"ratio2\"] == 0) & (df_ratio_test[\"ratio3\"] == 0)][\"gave\"]\ngroup_2_to_1 = df_ratio_test[df_ratio_test[\"ratio2\"] == 1][\"gave\"]\ngroup_3_to_1 = df_ratio_test[df_ratio_test[\"ratio3\"] == 1][\"gave\"]\n\n# T-tests\nt_stat_2, p_val_2 = ttest_ind(group_1_to_1, group_2_to_1)\nt_stat_3, p_val_3 = ttest_ind(group_1_to_1, group_3_to_1)\n\n# Print results\nprint(\"T-Test: 2:1 Match vs 1:1 Match\")\nprint(f\"  t-statistic = {t_stat_2:.4f}\")\nprint(f\"  p-value     = {p_val_2:.4f}\\n\")\n\nprint(\"T-Test: 3:1 Match vs 1:1 Match\")\nprint(f\"  t-statistic = {t_stat_3:.4f}\")\nprint(f\"  p-value     = {p_val_3:.4f}\")\n\n# Interpretation\nprint(\"\\nInterpretation:\")\nif p_val_2 &lt; 0.05 or p_val_3 &lt; 0.05:\n    print(\"There is a statistically significant difference in donation rates between groups.\")\n    print(\"However, the direction of the effect shows that higher match ratios (2:1 and 3:1) do NOT increase donation likelihood.\")\n    print(\"This supports the paper's claim on page 8 that 'larger match ratios... had no additional impact.'\")\nelse:\n    print(\"There is no statistically significant difference between the groups.\")\n    print(\"This confirms that increasing the match ratio beyond 1:1 does not lead to higher donation rates, as the authors suggest.\")\n\nT-Test: 2:1 Match vs 1:1 Match\n  t-statistic = -2.3020\n  p-value     = 0.0213\n\nT-Test: 3:1 Match vs 1:1 Match\n  t-statistic = -2.3636\n  p-value     = 0.0181\n\nInterpretation:\nThere is a statistically significant difference in donation rates between groups.\nHowever, the direction of the effect shows that higher match ratios (2:1 and 3:1) do NOT increase donation likelihood.\nThis supports the paper's claim on page 8 that 'larger match ratios... had no additional impact.'\n\n\n\n# Create 'ratio1' dummy: 1 if both ratio2 and ratio3 are 0 (i.e., it's a 1:1 match)\ndf_ratio_test[\"ratio1\"] = ((df_ratio_test[\"ratio2\"] == 0) & (df_ratio_test[\"ratio3\"] == 0)).astype(int)\n\n# Run regression\nmodel = smf.ols(\"gave ~ ratio1 + ratio2 + ratio3\", data=df_ratio_test).fit()\n\n# Display regression results\nprint(model.summary())\n\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                   gave   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     2.742\nDate:                Sat, 26 Apr 2025   Prob (F-statistic):             0.0416\nTime:                        12:13:15   Log-Likelihood:                 26629.\nNo. Observations:               50083   AIC:                        -5.325e+04\nDf Residuals:                   50079   BIC:                        -5.321e+04\nDf Model:                           3                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept   1.229e+10   1.54e+11      0.080      0.936   -2.89e+11    3.14e+11\nratio1     -1.229e+10   1.54e+11     -0.080      0.936   -3.14e+11    2.89e+11\nratio2     -1.229e+10   1.54e+11     -0.080      0.936   -3.14e+11    2.89e+11\nratio3     -1.229e+10   1.54e+11     -0.080      0.936   -3.14e+11    2.89e+11\n==============================================================================\nOmnibus:                    59815.680   Durbin-Watson:                   2.005\nProb(Omnibus):                  0.000   Jarque-Bera (JB):          4317584.682\nSkew:                           6.741   Prob(JB):                         0.00\nKurtosis:                      46.443   Cond. No.                     5.80e+14\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n[2] The smallest eigenvalue is 2.13e-25. This might indicate that there are\nstrong multicollinearity problems or that the design matrix is singular.\n\n\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\n\n# Drop missing values from the donation amount and treatment columns\ndf_amount = df.dropna(subset=[\"amount\", \"treatment\"])\n\n# --- T-TEST ---\ndonation_treatment = df_amount[df_amount[\"treatment\"] == 1][\"amount\"]\ndonation_control = df_amount[df_amount[\"treatment\"] == 0][\"amount\"]\n\nt_stat, p_val = ttest_ind(donation_treatment, donation_control)\n\nprint(\"T-Test: Donation Amount by Treatment\")\nprint(f\"  t-statistic = {t_stat:.4f}\")\nprint(f\"  p-value     = {p_val:.4f}\\n\")\n\n# --- LINEAR REGRESSION ---\nmodel = smf.ols(\"amount ~ treatment\", data=df_amount).fit()\nprint(\"Linear Regression: Donation Amount ~ Treatment\")\nprint(model.summary())\n\nT-Test: Donation Amount by Treatment\n  t-statistic = 1.8605\n  p-value     = 0.0628\n\nLinear Regression: Donation Amount ~ Treatment\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                  0.000\nMethod:                 Least Squares   F-statistic:                     3.461\nDate:                Sat, 26 Apr 2025   Prob (F-statistic):             0.0628\nTime:                        12:13:15   Log-Likelihood:            -1.7946e+05\nNo. Observations:               50083   AIC:                         3.589e+05\nDf Residuals:                   50081   BIC:                         3.589e+05\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept      0.8133      0.067     12.063      0.000       0.681       0.945\ntreatment      0.1536      0.083      1.861      0.063      -0.008       0.315\n==============================================================================\nOmnibus:                    96861.113   Durbin-Watson:                   2.008\nProb(Omnibus):                  0.000   Jarque-Bera (JB):        240735713.635\nSkew:                          15.297   Prob(JB):                         0.00\nKurtosis:                     341.269   Cond. No.                         3.23\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nIf the t-test or regression shows a statistically significant difference, it means that the treatment influenced the size of donations, not just whether people donated.\nIf not significant, then the treatment increased response rate, but not donation size, which aligns with the “extensive margin” effect described in behavioral economics.\n\n# Filter to people who made a donation (amount &gt; 0)\ndf_positive_donors = df[(df[\"amount\"] &gt; 0) & df[\"treatment\"].notna()]\n\n# --- T-TEST ---\ndonation_treatment = df_positive_donors[df_positive_donors[\"treatment\"] == 1][\"amount\"]\ndonation_control = df_positive_donors[df_positive_donors[\"treatment\"] == 0][\"amount\"]\n\nt_stat, p_val = ttest_ind(donation_treatment, donation_control)\n\nprint(\"T-Test (Donors Only): Donation Amount by Treatment\")\nprint(f\"  t-statistic = {t_stat:.4f}\")\nprint(f\"  p-value     = {p_val:.4f}\\n\")\n\n# --- REGRESSION ---\nmodel = smf.ols(\"amount ~ treatment\", data=df_positive_donors).fit()\nprint(\"Linear Regression (Donors Only): Donation Amount ~ Treatment\")\nprint(model.summary())\n\nT-Test (Donors Only): Donation Amount by Treatment\n  t-statistic = -0.5808\n  p-value     = 0.5615\n\nLinear Regression (Donors Only): Donation Amount ~ Treatment\n                            OLS Regression Results                            \n==============================================================================\nDep. Variable:                 amount   R-squared:                       0.000\nModel:                            OLS   Adj. R-squared:                 -0.001\nMethod:                 Least Squares   F-statistic:                    0.3374\nDate:                Sat, 26 Apr 2025   Prob (F-statistic):              0.561\nTime:                        12:13:16   Log-Likelihood:                -5326.8\nNo. Observations:                1034   AIC:                         1.066e+04\nDf Residuals:                    1032   BIC:                         1.067e+04\nDf Model:                           1                                         \nCovariance Type:            nonrobust                                         \n==============================================================================\n                 coef    std err          t      P&gt;|t|      [0.025      0.975]\n------------------------------------------------------------------------------\nIntercept     45.5403      2.423     18.792      0.000      40.785      50.296\ntreatment     -1.6684      2.872     -0.581      0.561      -7.305       3.968\n==============================================================================\nOmnibus:                      587.258   Durbin-Watson:                   2.031\nProb(Omnibus):                  0.000   Jarque-Bera (JB):             5623.279\nSkew:                           2.464   Prob(JB):                         0.00\nKurtosis:                      13.307   Cond. No.                         3.49\n==============================================================================\n\nNotes:\n[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n\n\nThis analysis isolates the intensive margin: how much people give once they’ve decided to donate.\nIf the treatment coefficient is not significant, it suggests the treatment affected whether people give (extensive margin), but not how much they give. If it’s significant, then the treatment changes the amount donated as well.\nYes, the treatment coefficient has a causal interpretation only if random assignment is preserved and we’re not conditioning on post-treatment behavior.\n\n# Keep only donors (amount &gt; 0)\ndf_donors = df[df[\"amount\"] &gt; 0]\n\n# Split into treatment and control groups\ntreatment_donors = df_donors[df_donors[\"treatment\"] == 1][\"amount\"]\ncontrol_donors = df_donors[df_donors[\"treatment\"] == 0][\"amount\"]\n\n# Calculate group means\nmean_treatment = treatment_donors.mean()\nmean_control = control_donors.mean()\n\n# Plotting\nplt.figure(figsize=(12, 5))\n\n# Control group plot\nplt.subplot(1, 2, 1)\nplt.hist(control_donors, bins=30, edgecolor='black')\nplt.axvline(mean_control, color='red', linestyle='dashed', linewidth=2, label=f\"Mean = ${mean_control:.2f}\")\nplt.title(\"Control Group Donations (Donors Only)\")\nplt.xlabel(\"Donation Amount ($)\")\nplt.ylabel(\"Frequency\")\nplt.legend()\n\n# Treatment group plot\nplt.subplot(1, 2, 2)\nplt.hist(treatment_donors, bins=30, edgecolor='black')\nplt.axvline(mean_treatment, color='red', linestyle='dashed', linewidth=2, label=f\"Mean = ${mean_treatment:.2f}\")\nplt.title(\"Treatment Group Donations (Donors Only)\")\nplt.xlabel(\"Donation Amount ($)\")\nplt.ylabel(\"Frequency\")\nplt.legend()\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "blog/hw1/hw1_questions.html#simulation-experiment",
    "href": "blog/hw1/hw1_questions.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic “works,” in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\n\n# Set seed for reproducibility\nnp.random.seed(42)\n\n# Simulate 10,000 Bernoulli draws for control (p = 0.018) and treatment (p = 0.022)\ncontrol_draws = np.random.binomial(n=1, p=0.018, size=10000)\ntreatment_draws = np.random.binomial(n=1, p=0.022, size=10000)\n\n# Calculate the differences between treatment and control draws\ndifferences = treatment_draws - control_draws\n\n# Compute the cumulative average of the differences\ncumulative_avg = np.cumsum(differences) / np.arange(1, len(differences) + 1)\n\n# Plotting\nplt.figure(figsize=(10, 5))\nplt.plot(cumulative_avg, color='orange', label='Cumulative Average of Differences')\nplt.axhline(y=0.004, color='red', linestyle='--', linewidth=2, label='True Treatment Effect (0.004)')\nplt.title(\"Simulation: Law of Large Numbers for Treatment Effect\")\nplt.xlabel(\"Number of Simulations\")\nplt.ylabel(\"Cumulative Average Difference\")\nplt.grid(True, linestyle='--', alpha=0.6)\nplt.legend()\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nThe orange line shows the cumulative average difference in donation rates over increasing sample sizes.\nThe red dashed line is the true average treatment effect: 0.022 - 0.018 = 0.004\nAt first, the cumulative difference is noisy — it jumps around. As more samples are included, the average “settles down” near the true effect of 0.004. This demonstrates that with large enough samples, random variation diminishes, revealing the true underlying effect.\n\n\nCentral Limit Theorem\n\n# Parameters\nsample_sizes = [50, 200, 500, 1000]\nnum_repeats = 1000\np_control = 0.018\np_treatment = 0.022\n\n# Set up subplots\nfig, axes = plt.subplots(1, 4, figsize=(18, 4), sharey=True)\n\n# Loop through each sample size\nfor i, n in enumerate(sample_sizes):\n    avg_diffs = []\n    for _ in range(num_repeats):\n        control = np.random.binomial(1, p_control, n)\n        treatment = np.random.binomial(1, p_treatment, n)\n        avg_diff = treatment.mean() - control.mean()\n        avg_diffs.append(avg_diff)\n\n    # Plot histogram of average treatment effects\n    ax = axes[i]\n    ax.hist(avg_diffs, bins=30, edgecolor='black', color='orange')\n    ax.axvline(np.mean(avg_diffs), color='red', linestyle='--', linewidth=2, label=\"Mean\")\n    ax.set_title(f\"Sample Size = {n}\")\n    ax.set_xlabel(\"Avg Treatment Effect\")\n    if i == 0:\n        ax.set_ylabel(\"Frequency\")\n\nplt.suptitle(\"Central Limit Theorem: Distribution of Average Treatment Effects\", fontsize=14)\nplt.tight_layout(rect=[0, 0, 1, 0.92])\nplt.show()\n\n\n\n\n\n\n\n\nEach plot shows the distribution of average treatment effects calculated from 1,000 repeated samples at different sample sizes: 50, 200, 500, and 1000.\nAs the sample size increases: 1. The distribution becomes less spread out (narrower) 2. The shape becomes more symmetric and bell-shaped, resembling a normal distribution 3. The mean converges around the true treatment effect (~0.004), shown by the red dashed line\nThis illustrates the CLT: the sampling distribution of the mean tends toward a normal distribution as sample size grows, regardless of the underlying data distribution."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Projects",
    "section": "",
    "text": "Balance Test\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHomework 1 - A/B Testing\n\n\n\n\nJay Lee\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHomework 2\n\n\n\n\nJay Lee\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA Replication of Karlan and List (2007)\n\n\n\n\nYour Name\nApr 26, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  }
]